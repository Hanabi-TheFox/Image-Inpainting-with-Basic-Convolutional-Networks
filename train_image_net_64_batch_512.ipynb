{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import pytorch_lightning as pl\n",
    "from image_inpainting.datamodule.image_net_data_module import ImageNetDataModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from image_inpainting.model.context_encoder import ContextEncoder\n",
    "from image_inpainting.utils import print_results_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "dm = ImageNetDataModule(\n",
    "    data_dir=os.path.join(data_dir, \"imagenet\"), \n",
    "    batch_size_train=512,\n",
    "    batch_size_val=512,\n",
    "    batch_size_test=512,\n",
    "    num_workers=10, \n",
    "    pin_memory=True, \n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ContextEncoder model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextEncoder(input_size=(3, 128, 128), hidden_size=4000, save_image_per_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load it from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ContextEncoder.load_from_checkpoint(\"checkpoints/imagenet_64/current_date=0-epoch=epoch=05-val_loss=val_loss=3.65.ckpt\") # change the path to your checkpoint\n",
    "# model.enable_save_image_per_epoch()\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/imagenet_64',\n",
    "    filename=now+'-{epoch:02d}-{val_loss:.2f}',\n",
    "    monitor='val_loss',\n",
    "    save_top_k=-1,  # Save all checkpoints\n",
    "    every_n_epochs=1  # Save checkpoint every n epochs\n",
    ")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"Context_Encoder_Inpainting\")\n",
    "trainer = pl.Trainer(max_epochs=300, devices=-1, accelerator=\"cuda\", logger=tb_logger, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, dm)\n",
    "\n",
    "# To continue training:\n",
    "# trainer.fit(model, dm, ckpt_path=\"checkpoints/imagenet_64/???.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook \"tensorboard\" exists if you want to check how the metrics evolve during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some images and evaluate the model performances\n",
    "\n",
    "Here the results of this cell are after ??? epochs on the full Image Net dataset cropped and resized to 64x64.\n",
    "\n",
    "- **Number of steps**: \n",
    "- **Time**: \n",
    "- **Observation (with tensorboard)**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dm)\n",
    "\n",
    "x, y = next(iter(dm.test_dataloader()))\n",
    "    \n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on test set\", dm.inverse_transform)\n",
    "\n",
    "dm.setup(\"fit\") # in case \"fit\" wasn't called before this cell\n",
    "\n",
    "x, y = next(iter(dm.train_dataloader()))\n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on training set\", dm.inverse_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on the best validation loss model\n",
    "\n",
    "Here the results of this cell are after ???? epochs on the full Image Net dataset cropped and resized to 64x64.\n",
    "\n",
    "\n",
    "- **Number of steps**: \n",
    "- **Time**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dm)\n",
    "\n",
    "x, y = next(iter(dm.test_dataloader()))\n",
    "    \n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on test set\", dm.inverse_transform)\n",
    "\n",
    "dm.setup(\"fit\") # in case \"fit\" wasn't called before this cell\n",
    "\n",
    "x, y = next(iter(dm.train_dataloader()))\n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on training set\", dm.inverse_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_inpainting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
