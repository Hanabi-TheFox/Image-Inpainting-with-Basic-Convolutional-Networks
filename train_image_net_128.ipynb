{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import pytorch_lightning as pl\n",
    "from image_inpainting.datamodule.image_net_data_module import ImageNetDataModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from image_inpainting.model.context_encoder import ContextEncoder\n",
    "from image_inpainting.utils import print_results_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "dm = ImageNetDataModule(\n",
    "    data_dir=os.path.join(data_dir, \"imagenet-128\"), \n",
    "    batch_size_train=512,\n",
    "    batch_size_val=512,\n",
    "    batch_size_test=512,\n",
    "    num_workers=10, \n",
    "    pin_memory=True, \n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ContextEncoder model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextEncoder(input_size=(3, 128, 128), hidden_size=4000, save_image_per_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load it from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ContextEncoder.load_from_checkpoint(\"checkpoints/imagenet_128_batch_512/2024-12-15_11-52-50-epoch=25-val_loss=5.48.ckpt\") # change the path to your checkpoint\n",
    "# model.enable_save_image_per_epoch()\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/imagenet_128',\n",
    "    filename=now+'-{epoch:02d}-{val_loss:.2f}',\n",
    "    monitor='val_loss',\n",
    "    save_top_k=-1,  # Save all checkpoints\n",
    "    every_n_epochs=1  # Save checkpoint every n epochs\n",
    ")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"Context_Encoder_Inpainting\")\n",
    "trainer = pl.Trainer(max_epochs=300, devices=-1, accelerator=\"cuda\", logger=tb_logger, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: The ImageNet dataset can't be downloaded automatically. Please refer to the README if you haven't already downloaded it. Otherwise you can skip this message.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)\n",
    "\n",
    "# To continue training:\n",
    "# trainer.fit(model, dm, ckpt_path=\"checkpoints/imagenet_128_batch_512/2024-12-15_11-52-50-epoch=25-val_loss=5.48.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook \"tensorboard\" exists if you want to check how the metrics evolve during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on the last epoch\n",
    "\n",
    "Here the results of this cell are after ????????? epochs on the full Image Net dataset cropped and resized to 128x128.\n",
    "\n",
    "- **Number of steps**: \n",
    "- **Time**: \n",
    "- **Observations (with tensorboard)**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"test\") # in case \"test\" wasn't called before this cell\n",
    "\n",
    "x, y = next(iter(dm.test_dataloader()))\n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on test set\", dm.inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"fit\") # in case \"fit\" wasn't called before this cell\n",
    "\n",
    "x, y = next(iter(dm.train_dataloader()))\n",
    "x = x.to(model.device)\n",
    "y = y.to(model.device)\n",
    "out = model.forward(x)\n",
    "\n",
    "print_results_images(x, y, out, \"Results on training set\", dm.inverse_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_inpainting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
